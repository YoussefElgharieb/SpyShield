{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d78808-3ea6-4f22-b01d-77d6343c0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# used in printing to a file\n",
    "import sys\n",
    "\n",
    "# GMM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# used to deep copy the global models to local models\n",
    "import copy\n",
    "\n",
    "# tracks progress of each loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Subset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb632c3-b0f1-4c2e-8c80-9bc402b3a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1368297158\n",
    "rng = np.random.default_rng(seed)\n",
    "seeds = rng.integers(low=0, high=2**32 - 1, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddf830-8aa1-4f7d-b6c9-0ac04864ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(train_dataset, test_dataset, num_clients, alpha):\n",
    "    def helper(dataset, proportions):\n",
    "        data = dataset.data\n",
    "        targets = dataset.targets\n",
    "        \n",
    "        num_classes = 10\n",
    "        indices_per_class = [[] for _ in range(num_classes)]\n",
    "        for idx in range(len(data)):\n",
    "            label = targets[idx].item()\n",
    "            indices_per_class[label].append(idx)\n",
    "        \n",
    "        client_indices = [[] for _ in range(num_clients)]\n",
    "        for c in range(num_classes):\n",
    "            rng = np.random.default_rng(seed)\n",
    "            rng.shuffle(indices_per_class[c])\n",
    "            class_splits = (np.cumsum(proportions[c]) * len(indices_per_class[c])).astype(int)[:-1]\n",
    "            client_splits = np.split(np.array(indices_per_class[c]), class_splits)\n",
    "            for client_id in range(num_clients):\n",
    "                client_indices[client_id].extend(client_splits[client_id])\n",
    "        \n",
    "        client_subsets = [Subset(dataset, indices) for indices in client_indices]\n",
    "        return client_subsets\n",
    "    \n",
    "    # Generate proportions for each class and client\n",
    "    rng = np.random.default_rng(seed)\n",
    "    proportions = rng.dirichlet(np.repeat(alpha, num_clients), size=10)\n",
    "    \n",
    "    train_client_subsets = helper(train_dataset, proportions)\n",
    "    test_client_subsets = helper(test_dataset, proportions)\n",
    "    \n",
    "    client_data = [(train_client_subsets[i], test_client_subsets[i]) for i in range(num_clients)]\n",
    "    \n",
    "    return client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58a518-d57c-45a5-8966-047bfb9044c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(dataset):\n",
    "    if(dataset == \"MNIST\"):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST('./data', train=True, download=False, transform=transform)\n",
    "    \n",
    "    elif(dataset == \"FashionMNIST\"):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.2860,), (0.3527,))\n",
    "        ])\n",
    "        train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa554d-150b-47f1-a77b-8450d7cb390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional neural network\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24331f2-7cf6-4e5d-8715-1f60b84fba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNIST, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf96981-4aed-4036-bed0-764ba0a59af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(dataset):\n",
    "    if(dataset == \"MNIST\"):\n",
    "        return MNIST()\n",
    "    elif(dataset == \"FashionMNIST\"):\n",
    "        return FashionMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f91606-1c14-4b7c-9bd7-7c20d45750e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, dataset, malicious, attack, epochs = 10, device = \"cuda\"):\n",
    "    \n",
    "    def randomWeights(model):\n",
    "        min_weight = float('inf')\n",
    "        max_weight = float('-inf')\n",
    "           \n",
    "        for param in model.parameters():\n",
    "            min_weight = min(min_weight, param.data.min().item())\n",
    "            max_weight = max(max_weight, param.data.max().item())\n",
    "    \n",
    "        for param in model.parameters():\n",
    "            param.data.uniform_(min_weight, max_weight)\n",
    "\n",
    "    \n",
    "    if malicious and attack == \"random weights\":\n",
    "        randomWeights(model)\n",
    "        return model.state_dict()\n",
    "\n",
    "    \n",
    "    data_loader = DataLoader(dataset, batch_size = 8, shuffle = True)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.0001 ,momentum=0.5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.995)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        batch_loss = []\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            # poisoning\n",
    "            if(malicious):\n",
    "                if(attack == \"random label flipping\"):\n",
    "                    for i in range(len(labels)):\n",
    "                        labels[i] = (labels[i] + rng.integers(1,10)) % 10\n",
    "                elif(attack == \"cyclic label flipping\"):\n",
    "                    for i in range(len(labels)):\n",
    "                        labels[i] = (labels[i] + 5)% 10\n",
    "                elif(attack == \"taregeted label flipping\"):\n",
    "                    for i in range(len(labels)):\n",
    "                        if (labels[i] == 1):\n",
    "                            labels[i] = 7\n",
    "                elif (attack == \"out of distribution\"):\n",
    "                    images = torch.randn_like(images)\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            log_probs = model(images)\n",
    "            loss = criterion(log_probs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "    return model.state_dict() #, epoch_grads #, (sum(epoch_loss) / len(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaed2ec-a0dd-47c8-a933-1b5282087dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, dataset, malicious = False, attack = \"random label flipping\", device = \"cuda\"):\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "    data_loader = DataLoader(dataset, batch_size = 8, shuffle=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "        \n",
    "        if(malicious):\n",
    "            if(attack == \"cyclic label flipping\"):\n",
    "                for i in range(len(labels)):\n",
    "                    labels[i] = (labels[i] + 5)% 10\n",
    "            elif(attack == \"taregeted label flipping\"):\n",
    "                    for i in range(len(labels)):\n",
    "                        if (labels[i] == 1):\n",
    "                            labels[i] = 7\n",
    "                        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        outputs = model(images)\n",
    "        batch_loss = F.cross_entropy(outputs, labels, reduction='sum')\n",
    "        loss += batch_loss.item()\n",
    "\n",
    "\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034ba2c-09d1-4162-83fb-d88f996bc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(weights, bias = 1):\n",
    "        aggregated_weights = copy.deepcopy(weights[0])\n",
    "        for key in aggregated_weights.keys():\n",
    "            for i in range(1,bias):\n",
    "                aggregated_weights[key] += weights[0][key]\n",
    "            for i in range(1, len(weights)):\n",
    "                aggregated_weights[key] += weights[i][key]\n",
    "            aggregated_weights[key] = torch.div(aggregated_weights[key], len(weights) + bias - 1)\n",
    "        return aggregated_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80d120-946d-4dee-88f9-17b94b18d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpyShield(\n",
    "    dataset,\n",
    "    clients_count, \n",
    "    clients_per_model,\n",
    "    clients_local_weights,\n",
    "    bias,\n",
    "    clients_datasets, \n",
    "    malicious_clients,  \n",
    "    attack, \n",
    "    criterion = \"accuracy\"):\n",
    "    \n",
    "    models_count = (clients_count - 1) // (clients_per_model - 1)\n",
    "    \n",
    "    def group(clients_count, clients_per_model):\n",
    "        # grouping\n",
    "        models_count = (clients_count - 1) // (clients_per_model - 1)\n",
    "        groups  = np.empty([clients_count, models_count], dtype = object)\n",
    "        groupings  = np.empty([clients_count, models_count], dtype = object)\n",
    "        rng = np.random.default_rng()\n",
    "        for i in range(clients_count):\n",
    "            remaining = np.delete(np.arange(clients_count), i)\n",
    "            for j in range(models_count):\n",
    "                    group = np.concatenate(([i],rng.choice(remaining, size= clients_per_model - 1, replace=False)))\n",
    "                    groups[i][j] = group\n",
    "                    remaining = np.delete(remaining, np.where(np.isin(remaining, group[1:])))\n",
    "\n",
    "        # mapping\n",
    "        while(True):\n",
    "            frequency = np.zeros(clients_count, dtype=int)\n",
    "            for i in range(clients_count):\n",
    "                for j in range(models_count):\n",
    "                    pairs = [(i, frequency[i]) for i in range(len(frequency))]\n",
    "                    filtered = []\n",
    "                    for pair in pairs:\n",
    "                        if pair[0] not in groups[i][j]:\n",
    "                            filtered.append(pair)\n",
    "                    rng.shuffle(filtered)\n",
    "                    assignee = min(filtered, key=lambda x: x[1])[0]\n",
    "                    groupings[i][j] = (groups[i][j], assignee)\n",
    "                    # update the frequcny \n",
    "                    frequency[assignee] += 1;\n",
    "            if(np.all(frequency == models_count)):\n",
    "                break\n",
    "        return groupings\n",
    "\n",
    "    def test(\n",
    "        dataset,\n",
    "        clients_count, \n",
    "        models_count, \n",
    "        groupings, \n",
    "        clients_local_weights,\n",
    "        bias,\n",
    "        clients_datasets, \n",
    "        malicious_clients,\n",
    "        attack, \n",
    "        criterion):\n",
    "        # intialize the results 2D list\n",
    "        results = np.empty([clients_count, models_count])\n",
    "        for i in tqdm(range(clients_count)):\n",
    "            for j in range(models_count):\n",
    "            \t# aggregate weights of clients in the jth group of the ith client        \n",
    "                aggregated_weights = aggregate(weights = [clients_local_weights[index] for index in groupings[i][j][0] ], bias = bias)\n",
    "            \t# intialize the model using the aggregated weights\n",
    "                model = Model(dataset)\n",
    "                model.load_state_dict(aggregated_weights)\n",
    "            \t# test the model at the respective tester client\n",
    "                results[i][j] = testModel(\n",
    "                    model,\n",
    "                    clients_datasets[groupings[i][j][1]][1],\n",
    "                    groupings[i][j][1] in malicious_clients,\n",
    "                    attack)[0 if criterion == \"accuracy\" else 1]  \n",
    "        return results;\n",
    "    \n",
    "    def evaluateTesters(clients_count, models_count, groupings, results, criterion):\n",
    "        # prepare the results to test for reliability\n",
    "        # intialize results_per_tester\n",
    "        results_per_tester = [[] for i in range(clients_count)]\n",
    "        # populate results_per_tester\n",
    "        for i in range(clients_count):\n",
    "            for j in range(models_count):\n",
    "                results_per_tester[groupings[i][j][1]].append(results[i][j])\n",
    "        # intialize mean_result_per_tester\n",
    "        mean_result_per_tester = [np.mean(results) for results in results_per_tester]\n",
    "        # index mean_result_per_tester\n",
    "        indexed_mean_results_per_tester = [[index, mean_result_per_tester[index]] for index in range(clients_count)]\n",
    "        # sort indexed_mean_results_per_tester\n",
    "        indexed_mean_results_per_tester = sorted(indexed_mean_results_per_tester, key = lambda x: x[1])\n",
    "        # testers in the second half of mean_result are considered reliable if the criterion is accuracy.\n",
    "        # testers in the first half of mean_result are considered reliable if the criterion is loss.\n",
    "        reliable = [index for index,_ in (indexed_mean_results_per_tester[int(clients_count/2) + 2:] if criterion == \"accuracy\" else indexed_mean_results_per_tester[: int(clients_count/2) - 2])]        \n",
    "        \n",
    "        return reliable\n",
    "\n",
    "    def evaluateTestees(clients_count, models_count, groupings, reliable, results, criterion):\n",
    "        # intialize results_per_testee\n",
    "        results_per_testee = [[] for i in range(clients_count)]\n",
    "        for i in range(clients_count):\n",
    "            for j in range(models_count):\n",
    "                if(groupings[i][j][1] in reliable):\n",
    "                    results_per_testee[i].append(results[i][j])\n",
    "        # intialize mean_result_per_testee\n",
    "        mean_result_per_testee = [(np.mean(results) if len(results) > 0 else 0 ) for results in results_per_testee]\n",
    "        # index mean_result_per_testee\n",
    "        indexed_mean_results_per_testee = [[index, mean_result_per_testee[index]] for index in range(clients_count)]\n",
    "        # sort indexed_mean_results_per_testee\n",
    "        indexed_mean_results_per_testee = sorted(indexed_mean_results_per_testee, key = lambda x: x[1])\n",
    "        # testees in the second half of mean_result are considered honest if the criterion is accuracy.\n",
    "        # testees in the first half of mean_result are considered honest if the criterion is loss.\n",
    "        honest = [index for index,_ in (indexed_mean_results_per_testee[int(clients_count/2) + 2: ] if criterion == \"accuracy\" else indexed_mean_results_per_testee[: int(clients_count/2) - 2])]\n",
    "\n",
    "\n",
    "        # analysis\n",
    "        mean_result_per_poisoned_testee = [mean_result_per_testee[i] for i in range(clients_count) if i in malicious_clients]\n",
    "        \n",
    "        plot(mean_result_per_testee, mean_result_per_poisoned_testee, criterion)\n",
    "\n",
    "        return honest\n",
    "\n",
    "    \n",
    "    groupings = group(clients_count, clients_per_model)\n",
    "    \n",
    "    results = test(\n",
    "        dataset,\n",
    "        clients_count, \n",
    "        models_count, \n",
    "        groupings, \n",
    "        clients_local_weights,\n",
    "        bias,\n",
    "        clients_datasets, \n",
    "        malicious_clients, \n",
    "        attack, \n",
    "        criterion)\n",
    "\n",
    "    reliable = evaluateTesters(clients_count, models_count, groupings, results, criterion)\n",
    "    \n",
    "    indices = evaluateTestees(clients_count, models_count, groupings, reliable, results, criterion)\n",
    "\n",
    "\n",
    "    return indices, reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f9021-1a86-4dc4-95e8-7f5f62599241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiKrum(weights, d=1):\n",
    "\n",
    "    n = len(weights)\n",
    "\n",
    "    # Calculate squared Euclidean distances\n",
    "    distances = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            model1 = global_model = Model(\"FashionMNIST\")\n",
    "            model1.load_state_dict(weights[i])\n",
    "            model2 = global_model = Model(\"FashionMNIST\")\n",
    "            model2.load_state_dict(weights[j])\n",
    "            model1_params = list(model1.parameters())\n",
    "            model2_params = list(model2.parameters())\n",
    "            \n",
    "            model1_flat = torch.cat([param.flatten() for param in model1_params])\n",
    "            model2_flat = torch.cat([param.flatten() for param in model2_params])\n",
    "            \n",
    "            # Calculate the difference\n",
    "            diff = model1_flat - model2_flat\n",
    "            distances[i][j] = torch.linalg.vector_norm(diff)\n",
    "\n",
    "    indexed_distances = []\n",
    "    for i in range(n):\n",
    "        sorted_distances = np.sort(distances[i])\n",
    "        indexed_distances.append((i, np.sum(sorted_distances[:n - int(n/2)])))\n",
    "\n",
    "\n",
    "    sorted_indexed_distances = sorted(indexed_distances, key=lambda x: x[1])\n",
    "    sorted_indices = [indexed_distance[0] for indexed_distance in sorted_indexed_distances]\n",
    "    # index of  the client with the minimum sum of distances\n",
    "    return sorted_indices[:d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb3bcf-eab9-48f1-9865-7c9d475578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Krum(weights):\n",
    "\n",
    "    return MultiKrum(weights)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc57b93-1c24-4c1e-85dc-d068a4b0348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Median(weights):\n",
    "    n = len(weights)\n",
    "    global_model = Model(\"FashionMNIST\")\n",
    "    \n",
    "    # Get the keys of the state dict\n",
    "    keys = weights[0].keys()\n",
    "    \n",
    "    # Initialize a state dict to store the median parameters\n",
    "    median_weights = {key: torch.zeros_like(weights[0][key]) for key in keys}\n",
    "    \n",
    "    # Compute the median for each parameter\n",
    "    for key in keys:\n",
    "        stacked_params = torch.stack([weights[i][key].flatten() for i in range(n)])\n",
    "        median_params = torch.median(stacked_params, dim=0).values\n",
    "        median_weights[key] = median_params.view_as(weights[0][key])\n",
    "    \n",
    "    return median_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f4064-237e-467e-be85-3b9163f6fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrimmedMean(weights, trim_ratio=0.25):\n",
    "    n = len(weights)\n",
    "    global_model = Model(\"FashionMNIST\")\n",
    "    \n",
    "    # Get the keys of the state dict\n",
    "    keys = weights[0].keys()\n",
    "    \n",
    "    # Initialize a state dict to store the trimmed mean parameters\n",
    "    trimmed_mean_weights = {key: torch.zeros_like(weights[0][key]) for key in keys}\n",
    "    \n",
    "    # Compute the trimmed mean for each parameter\n",
    "    for key in keys:\n",
    "        stacked_params = torch.stack([weights[i][key].flatten() for i in range(n)])\n",
    "        \n",
    "        # Sort the parameters for each element\n",
    "        sorted_params, _ = torch.sort(stacked_params, dim=0)\n",
    "        \n",
    "        # Calculate the indices to trim\n",
    "        trim_n = int(trim_ratio * n)\n",
    "        trimmed_params = sorted_params[ trim_n + 1 : n - trim_n - 1, :].float()\n",
    "        \n",
    "        # Compute the mean of the remaining parameters\n",
    "        trimmed_mean_params = trimmed_params.mean(dim=0)\n",
    "        trimmed_mean_weights[key] = trimmed_mean_params.view_as(weights[0][key])\n",
    "    \n",
    "    return trimmed_mean_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fa94f-3474-405b-b845-eec3f53d72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data1, data2, criterion):\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plot histograms for both datasets, using different colors and alpha for transparency\n",
    "    \n",
    "    if(criterion == 'loss'):\n",
    "        ax.hist(data1, label='honest', bins=(20) ,color='b', hatch='O', align='right')\n",
    "        ax.hist(data2, alpha=0.8, label='poisoned', bins=20, color='r', hatch='.' , align='right')\n",
    "    else:\n",
    "        ax.hist(data1, label='honest', range =(0,0.9), bins=(20) , color='b', hatch='O', align='right')\n",
    "        ax.hist(data2, alpha=0.8, label='poisoned',  range =(0,0.9), bins=20, color='r', hatch='.', align='right')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    plt.ylabel('clients count')\n",
    "    plt.xlabel(criterion)\n",
    "    \n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca71af-3512-442e-ab51-428e5606dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, clients_count, malicious_clients_count,  attack, algorithm, algorithm_parameters, device = \"cuda\"):    \n",
    "    \n",
    "    train_dataset, test_dataset = getDataset(dataset)\n",
    "    \n",
    "    \n",
    "    clients_datasets = sample(train_dataset, test_dataset, 150, 0.5)\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(clients_datasets)\n",
    "    \n",
    "    clients_datasets = clients_datasets[0: clients_count]\n",
    "            \n",
    "    # intialize model\n",
    "    global_model = Model(dataset)\n",
    "    global_model.to(device)\n",
    "    epoch = 0\n",
    "    \n",
    "    metrics = []\n",
    "    while (epoch < 250):\n",
    "        print(\"epoch: \", epoch + 1)\n",
    "        # intialize the dictionary of malicious clients\n",
    "        rng = np.random.default_rng(seeds[epoch])\n",
    "        malicious_clients = rng.choice(np.arange(clients_count), size = malicious_clients_count, replace = False)\n",
    "        # print(malicious_clients)\n",
    "        # intialize local wieghts list \n",
    "        clients_local_weights = []\n",
    "        for i in tqdm(range(clients_count)):\n",
    "            # train the ith client \n",
    "            weights = trainModel(\n",
    "                copy.deepcopy(global_model), \n",
    "                clients_datasets[i][0], \n",
    "                i in malicious_clients, \n",
    "                attack)\n",
    "            # append the ith client's local weights to local_wieghts list\n",
    "            clients_local_weights.append(weights)\n",
    "\n",
    "        stats ={}\n",
    "        if(algorithm == \"FedAvg\"):\n",
    "            global_model.load_state_dict(aggregate(clients_local_weights))\n",
    "            \n",
    "        elif(algorithm == \"SpyShield\"):\n",
    "            indices, relibale = SpyShield(\n",
    "                dataset,\n",
    "                clients_count, \n",
    "                algorithm_parameters[\"clients_per_model\"],\n",
    "                clients_local_weights,\n",
    "                algorithm_parameters[\"bias\"],\n",
    "                clients_datasets, \n",
    "                malicious_clients,  \n",
    "                attack, \n",
    "                algorithm_parameters[\"criterion\"])\n",
    "    \n",
    "            global_model.load_state_dict(aggregate([clients_local_weights[i] for i in indices]))\n",
    "\n",
    "            # log\n",
    "            # intialize true_positives_unreliable\n",
    "            true_positives_unreliable = 0\n",
    "            # count true_positives_unreliable\n",
    "            if(attack == \"cyclic label flipping\" or attack == \"targeted label flipping\"):\n",
    "                for i in range(clients_count):\n",
    "                    if i not in relibale and i in malicious_clients:\n",
    "                        true_positives_unreliable += 1\n",
    "                stats[\"true_positives_unreliable\"] = true_positives_unreliable\n",
    "                \n",
    "            # intialize true_positives_poisoned\n",
    "            true_positives_poisoned = 0\n",
    "            # count true_positives_malicious\n",
    "            for i in range(clients_count):\n",
    "                if i not in indices and i in malicious_clients:\n",
    "                    true_positives_poisoned += 1\n",
    "            stats[\"true_positives_poisoned\"] = true_positives_poisoned\n",
    "                \n",
    "        elif (algorithm == \"Krum\"):\n",
    "            index = Krum(clients_local_weights)\n",
    "            global_model.load_state_dict(clients_local_weights[index])\n",
    "\n",
    "            # log\n",
    "            stats[\"is_selected_poisoned\"] = index in malicious_clients\n",
    "            \n",
    "            \n",
    "        elif (algorithm == \"MultiKrum\"):\n",
    "            indices = MultiKrum(clients_local_weights, algorithm_parameters[\"d\"])\n",
    "            global_model.load_state_dict(aggregate([clients_local_weights[i] for i in indices]))\n",
    "\n",
    "            # log\n",
    "            false_negatives_poisoned = 0\n",
    "            for index in indices:\n",
    "                if index in malicious_clients:\n",
    "                    false_negatives_poisoned += 1\n",
    "        \n",
    "            stats[\"false_negative_poisoned\"] =  false_negatives_poisoned\n",
    "            \n",
    "        elif (algorithm == \"Median\"):\n",
    "            median_weights = Median(clients_local_weights)\n",
    "            global_model.load_state_dict(median_weights)\n",
    "\n",
    "        elif (algorithm == \"TrimmedMean\"):\n",
    "            trimmed_mean_weights = TrimmedMean(clients_local_weights)\n",
    "            global_model.load_state_dict(trimmed_mean_weights)\n",
    "\n",
    "        \n",
    "        accuracies, losses = [], []\n",
    "        for i in range(clients_count):\n",
    "            accuracy, loss = testModel(global_model, clients_datasets[i][1], malicious = False)\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_loss = np.mean(loss)\n",
    "        \n",
    "        metrics.append([mean_accuracy, mean_loss, stats])\n",
    "        print(metrics)\n",
    "        \n",
    "        epoch += 1\n",
    "    return global_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a977ca-3230-436e-b2a2-a97f00163603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3604b-d56e-400a-98a1-b516a3fd2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm_parameters = {\"d\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374c2ea-f7c1-4574-93c9-faa42ee82db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_parameters = {\n",
    "    \"clients_per_model\": 4,\n",
    "    \"bias\": 9,\n",
    "    \"criterion\":\"loss\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7dcc98-2c48-487b-942f-f2f40bf67839",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset\": \"FashionMNIST\",\n",
    "    \"clients_count\": 50,\n",
    "    \"malicious_clients_count\": 10,\n",
    "    \"attack\":\"cyclic label flipping\",\n",
    "    \"algorithm\": \"SpyShield\",\n",
    "    \"algorithm_parameters\": algorithm_parameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c96a44-9d3f-4e73-a41f-558325c2a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adf481-2d7b-4ec7-a64c-18a20a784509",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253712e-b020-4c23-bd7e-bdf448aa5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54bb1d-c503-46a6-9761-38358c457402",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder += str(config[\"clients_count\"]) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631acbc-fc55-4778-98ee-375c72274be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21ab37-df4f-4866-850d-15cefa4817ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder += config[\"attack\"] + \"/\" if config[\"malicious_clients_count\"] > 0 else \"no-attack/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489623f-3e90-4110-9ac7-83d3c6b66841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644e84a-6cc8-422e-8f2e-5431ac8d8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = config[\"algorithm\"] +  \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906f9ce-b159-4c7d-bc6e-906e7caa4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5037104-7cd4-4f48-a694-c422de135f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model, metrics = main(\n",
    "    config[\"dataset\"], \n",
    "    config[\"clients_count\"],\n",
    "    config[\"malicious_clients_count\"],\n",
    "    config[\"attack\"],\n",
    "    config[\"algorithm\"],\n",
    "    config[\"algorithm_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305a3ae-3ba8-4170-a2d8-e67e03d5cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + file, 'a') as data:\n",
    "    data.write(\"config =\" + str(config) + \"\\n\")\n",
    "    data.write(\"metrics =\" + str(metrics) + \"\\n\")\n",
    "    data.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
